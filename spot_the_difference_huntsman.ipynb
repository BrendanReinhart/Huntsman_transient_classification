{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Transient Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import itertools\n",
    "import subprocess\n",
    "import ccdproc\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import sys\n",
    "import shutil as shutil\n",
    "from shutil import move\n",
    "import pyfits\n",
    "from astropy.convolution import Gaussian2DKernel, convolve\n",
    "import ephem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can add the below process to the existing Transients code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This section tells the code where the files are. \n",
    "#data_path should point to the directory that holds the .resamp.fits files \n",
    "#produced by swarp (usually by Jack's Code)\n",
    "data_path = ('./output/Temp/')\n",
    "\n",
    "#master_file is the final processed image made from the above resamp files.\n",
    "master_file = ['./output/coadd_ngc300_r.fits']\n",
    "\n",
    "#master_weight is the weight file which corresponds to the above master file.\n",
    "master_weight = ['./output/coadd_ngc300_r.weight.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These variables are lists of the resampled files and their corresponding weights.\n",
    "\n",
    "resamps=sorted(glob.glob(data_path+'*.resamp.fits'))\n",
    "weights=sorted(glob.glob(data_path+'*.resamp.weight.fits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates a segmentation map from the master file. This will be used to generate flag files later.\n",
    "#To tweak the sensitivity of this segmentation map (brightness of objects it identifies for flagging), change\n",
    "#the DETECT_THRESH and ANALYSIS_THRESH values in segmentation.sex, located in the config_files directory.\n",
    "#This file is a temporary file, but the code will not delete it by default, as it can be a useful analysis tool.\n",
    "\n",
    "subprocess.call('sex '+master_file[0]+' -c ./config_files/segmentation.sex -WEIGHT_IMAGE '+master_weight[0], shell=True)\n",
    "subprocess.call('mv ./Processed_Images/Temp/check.fits ./Processed_Images/Temp/segmentation_map_ref.fits', shell=True)\n",
    "master_segmentation = ['./Processed_Images/Temp/segmentation_map_ref.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This loop creates all the difference images and their respective object, background, and aperture maps.\n",
    "\n",
    "for i in range(0,2):#len(resamps)):\n",
    "    reference=fits.open(master_file[0])\n",
    "    resampled=fits.open(resamps[i])\n",
    "    \n",
    "    #measures the distance from the central WCS pixel to the right and to the bottom of the image, respectively.\n",
    "    resdistx=(resampled[0].header['NAXIS1']-resampled[0].header['CRPIX1'])\n",
    "    resdisty=(resampled[0].header['NAXIS2']-resampled[0].header['CRPIX2'])\n",
    "    \n",
    "    #Creates difference values that represent the start and end pixels of the resampled image on the reference image.\n",
    "    ref_x_start=int(reference[0].header['CRPIX1']-resampled[0].header['CRPIX1'])\n",
    "    ref_y_start=int(reference[0].header['CRPIX2']-resampled[0].header['CRPIX2'])\n",
    "    ref_x_end=int(reference[0].header['CRPIX1']+resdistx)\n",
    "    ref_y_end=int(reference[0].header['CRPIX2']+resdisty)\n",
    "    \n",
    "    #loading files into memory\n",
    "    refimg=pyfits.open(master_file[0])\n",
    "    resimg=pyfits.open(resamps[i])\n",
    "    segimg=pyfits.open(master_segmentation[0])\n",
    "    \n",
    "    #converting to array\n",
    "    D1=refimg[0].data\n",
    "    D2=resimg[0].data\n",
    "    D3=segimg[0].data\n",
    "    \n",
    "    #resizing and scaling pixel values\n",
    "    resize_ref=D1[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    resamp_scaled=D2*resampled[0].header['FLXSCALE']\n",
    "    resize_seg=D3[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    \n",
    "    #doing the subtraction of the reference image from the resampled\n",
    "    out_file=resamp_scaled-resize_ref\n",
    "    \n",
    "    #loading header information from original resampled image. This will be saved into the new images.\n",
    "    head=pyfits.getheader(resamps[i])\n",
    "    \n",
    "    #loads the filename of the resamp image into a variable, then deletes .resamp.fits from the end of it.\n",
    "    #This allows the code to write new files with the same naming format, but different file extension names.\n",
    "    #If your files don't end in .resamp.fits, the -12 will need to be changed to match the number of characters\n",
    "    #in the file extension.\n",
    "    path=os.path.basename(resamps[i])\n",
    "    new_path=path[:-12]\n",
    "    \n",
    "    #saves the final difference file, and the temporary resized segmentation map.\n",
    "    pyfits.writeto(('./Processed_Images/'+new_path+'.difference.fits'), out_file, head)\n",
    "    pyfits.writeto(('./Processed_Images/Temp/temp_segment.fits'), resize_seg, head)\n",
    "    \n",
    "    #produces a flag map from the temporary segmentation map.\n",
    "    subprocess.call('ww -c ./config_files/default.ww -WEIGHT_NAMES '+weights[i]+',./Processed_Images/Temp/temp_segment.fits', shell=True)\n",
    "    \n",
    "    #does the main sextractor run on the subtracted file, producing the object, background, and aperture files.\n",
    "    #this is controlled by default.sex in the config_files directory\n",
    "    subprocess.call('sex ./Processed_Images/'+new_path+'.difference.fits -c ./config_files/default.sex', shell=True)\n",
    "    \n",
    "    #cleans up temporary files and renames background, object, and aperture files. \n",
    "    subprocess.call('rm ./Processed_Images/Temp/temp_segment.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check.fits ./Processed_Images/'+new_path+'.background.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check2.fits ./Processed_Images/'+new_path+'.object.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check3.fits ./Processed_Images/'+new_path+'.apertures.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/weight.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/flag.fits',shell=True)\n",
    "#Uncomment the next line if you would like the code to automatically clean up the master segmentation map.\n",
    "#subprocess.call('rm ./Processed_Images/Temp/segmentation_map_ref.fits',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Begin Brendan's Transient checking script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is where the code can be tacked onto the pipeline, after subtracting reference images.\n",
    "# At this point we should have a combined image, with reference subtracted, where the only point sources remaining\n",
    "# (in theory) are transients such as supernovae or asteroids.\n",
    "\n",
    "# This code aims to identify such sources as either asteroids or anomalies, which can then be manually followed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SExtractor once more to spot remaining (transient) sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate list of sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check against catalogues of known asteroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download latest MPCORB catalogue from:\n",
    "# www.minorplanetcenter.org/iau/MPCORB/MPCORB.DAT\n",
    "\n",
    "# Full list of paramters and how to read the data:\n",
    "# http://www.minorplanetcenter.net/iau/info/MPOrbitFormat.html\n",
    "\n",
    "\n",
    "# and do a manual check using PYEPHEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00004', '3.20', '0.32', 'K161D', '129.52980', '151.13748',\n",
       "       '103.84611', '7.14005', '0.0889223', '0.27156600', '2.3616695', '0',\n",
       "       'MPO358623', '6811', '98', '1821-2015', '0.60', 'M-p', '18h',\n",
       "       'MPCLINUX', '0000', '(4) Vesta', '20151215'], \n",
       "      dtype='|S11')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MPCORB.DAT data into an array:\n",
    "# delimiter to split data into required columns\n",
    "# Add 'skip_header=41' parameter when using real data to skip header info\n",
    "# names = ['designation', 'abs mag', 'slope param', 'epoch', 'mean epoch anomaly', 'perihelion arg', 'longitude', 'inclination', 'eccentricity', 'mean daily motion', 'semimajor axis', 'uncertainty', 'reference', 'num obs', 'num opp', 'obs years / arc length', 'rms', 'coarse perturb', 'precise perturb', 'comp name', '4hex flag', 'readable designation',\n",
    "# 'last obs']\n",
    "MPCORB = np.genfromtxt('MPCORB/MPCORB_test', autostrip=True, dtype=str,  delimiter = [8,6,6,6,10,11,11,11,11,12,12,3,10,6,4,10,5,4,4,11,5,28,8])\n",
    "MPCORB[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search MPCORB for matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nest this loop outside the MPCORB search loop:\n",
    "# for trans in translist:\n",
    "    # RA = trans.header[\"RA\"]\n",
    "    # DEC = trans.header[\"DEC\"]\n",
    "    # obstime = trans.header[\"DATE\"]\n",
    "    # identcount = 0\n",
    "    # for object in MPCORB:\n",
    "        # .......\n",
    "    \n",
    "    # if identcount = 0 (no object found):\n",
    "        # anom.append(\"object designation\", \"object name\" \"trans WCS at that time\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required orbital params:\n",
    "\n",
    "N (= Om) = longitude of the ascending node \n",
    "\n",
    "i (= inc) = inclination to the ecliptic (plane of the Earth's orbit)\n",
    "\n",
    "w (= om) = argument of perihelion\n",
    "\n",
    "a = semi-major axis, or mean distance from Sun\n",
    "\n",
    "e = eccentricity (0=circle, 0-1=ellipse, 1=parabola)\n",
    "\n",
    "M = mean anomaly (0 at perihelion; increases uniformly with time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiddling around with pyephem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to extract the packed date format given in the MPCORB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define dictionary of alpha to numbers for MPCORB packed dates translation:\n",
    "# http://www.minorplanetcenter.net/iau/info/PackedDates.html\n",
    "\n",
    "def dateextract(date):\n",
    "    packeddates = {'1':'1', '2':'2', '3':'3', '4':'4', '5':'5', '6':'6', '7':'7', '8':'8', '9':'9', \\\n",
    "                   '0':'0', 'A':'10', 'B':'11', 'C':'12', 'D':'13', 'E':'14', 'F':'15', 'G':'16', \\\n",
    "                   'H':'17', 'I':'18', 'J':'19', 'K':'20', 'L':'21', 'M':'22', 'N':'23', 'O':'24', \\\n",
    "                   'P':'25', 'Q':'26', 'R':'27', 'S':'28','T':'29', 'U':'30', 'V':'31' \\\n",
    "              }\n",
    "    datestring = list(date)\n",
    "    datestring2 = \"\"\n",
    "    for i in range(len(datestring)):\n",
    "        char = packeddates['%s' % datestring[i]]\n",
    "        datestring[i] = char\n",
    "        datestring2 += str(datestring[i])\n",
    "    # now conjoin array back to string, as a date format required by ephem.. eg \n",
    "    return datestring2\n",
    "    \n",
    "    print(datestring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2016113'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateextract('K161D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some asteroid parameters into pyephem to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00004' '3.20' '0.32' 'K161D' '129.52980' '151.13748' '103.84611'\n",
      " '7.14005' '0.0889223' '0.27156600' '2.3616695' '0' 'MPO358623' '6811' '98'\n",
      " '1821-2015' '0.60' 'M-p' '18h' 'MPCLINUX' '0000' '(4) Vesta' '20151215']\n",
      "103:50:46.0 7:08:24.2 151:08:14.9 2.36166954041 0.0889223 129:31:47.3\n"
     ]
    }
   ],
   "source": [
    "# initialise a new, blank orbital body and load orbital params:\n",
    "params = MPCORB[0]\n",
    "body = ephem.EllipticalBody()\n",
    "\n",
    "#six required params for Keplerian orbit:\n",
    "body._Om = float(params[6])\n",
    "body._inc = float(params[7])\n",
    "body._om = float(params[5])\n",
    "body._a = float(params[10])\n",
    "body._e = float(params[8])\n",
    "body._M = float(params[4])\n",
    "\n",
    "#and mean daily motion n required too:\n",
    "mdm = aasdasdsads\n",
    "\n",
    "# Correction for precession:\n",
    "N = N_Epoch + 0.013967 * ( 2000.0 - Epoch ) + 3.82394E-5 * d\n",
    "\n",
    "\n",
    "print(params)\n",
    "print(body._Om, body._inc, body._om, body._a, body._e, body._M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correction for precession\n",
    "N = params[6]\n",
    "\n",
    "# NEEDTO FIND A WAY TO CONVERT THE PACKED EPOCH FORM TO A DATE TO MAKE THIS CORRECTION UNIVERSAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using orbital params, predict location in sky of object at certain time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "For MP in MPCORB:\n",
    "    inc = \n",
    "     = \n",
    "    newobject = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    # convert orbital params at given date to RA/DEC\n",
    "    # Vec = vectorize (trans RA & DEC) with (MPCORB object RA & DEC)\n",
    "    # if Vec <= threshold (20 arcmin?):\n",
    "        # ident.append(\"object designation\", \"object name\" \"object WCS at that time\", \"distance vector from trans\")\n",
    "        # identcount += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dates must be initialized from a number, string, tuple, or datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-642fd829b0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mephem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2004/4/20\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dates must be initialized from a number, string, tuple, or datetime"
     ]
    }
   ],
   "source": [
    "m = ephem.Sun()\n",
    "m.compute(\"2004/4/20\")\n",
    "m.ra, m.dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dates must be initialized from a number, string, tuple, or datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-82f600b32343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mephem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2004/3/27\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: dates must be initialized from a number, string, tuple, or datetime"
     ]
    }
   ],
   "source": [
    "print(ephem.Date(\"2004/3/27\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1899/12/31 21:18:04\n"
     ]
    }
   ],
   "source": [
    "print(ephem.Date(0.3875488833))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pyephem, take WCS of anomalies, if pyephem of each oject in MPCORB is within a threshold (vectorize) at that time, then return object\n",
    "# else, return anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "print(len('00001    3.34  0.12 K161D 181.38133   72.73324   80.32180   10.59166  0.0757544  0.21400734   2.7681117  0 MPO358623  6592 109 1801-2015 0.60 M-v 30h MPCLINUX   0000      (1) Ceres              20151128'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
