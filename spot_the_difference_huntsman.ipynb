{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Transient Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import itertools\n",
    "import subprocess\n",
    "import ccdproc\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import sys\n",
    "import shutil as shutil\n",
    "from shutil import move\n",
    "import pyfits\n",
    "from astropy.convolution import Gaussian2DKernel, convolve\n",
    "import ephem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can add the below process to the existing Transients code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This section tells the code where the files are. \n",
    "#data_path should point to the directory that holds the .resamp.fits files \n",
    "#produced by swarp (usually by Jack's Code)\n",
    "data_path = ('./output/Temp/')\n",
    "\n",
    "#master_file is the final processed image made from the above resamp files.\n",
    "master_file = ['./output/coadd_ngc300_r.fits']\n",
    "\n",
    "#master_weight is the weight file which corresponds to the above master file.\n",
    "master_weight = ['./output/coadd_ngc300_r.weight.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These variables are lists of the resampled files and their corresponding weights.\n",
    "\n",
    "resamps=sorted(glob.glob(data_path+'*.resamp.fits'))\n",
    "weights=sorted(glob.glob(data_path+'*.resamp.weight.fits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates a segmentation map from the master file. This will be used to generate flag files later.\n",
    "#To tweak the sensitivity of this segmentation map (brightness of objects it identifies for flagging), change\n",
    "#the DETECT_THRESH and ANALYSIS_THRESH values in segmentation.sex, located in the config_files directory.\n",
    "#This file is a temporary file, but the code will not delete it by default, as it can be a useful analysis tool.\n",
    "\n",
    "subprocess.call('sex '+master_file[0]+' -c ./config_files/segmentation.sex -WEIGHT_IMAGE '+master_weight[0], shell=True)\n",
    "subprocess.call('mv ./Processed_Images/Temp/check.fits ./Processed_Images/Temp/segmentation_map_ref.fits', shell=True)\n",
    "master_segmentation = ['./Processed_Images/Temp/segmentation_map_ref.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This loop creates all the difference images and their respective object, background, and aperture maps.\n",
    "\n",
    "for i in range(0,2):#len(resamps)):\n",
    "    reference=fits.open(master_file[0])\n",
    "    resampled=fits.open(resamps[i])\n",
    "    \n",
    "    #measures the distance from the central WCS pixel to the right and to the bottom of the image, respectively.\n",
    "    resdistx=(resampled[0].header['NAXIS1']-resampled[0].header['CRPIX1'])\n",
    "    resdisty=(resampled[0].header['NAXIS2']-resampled[0].header['CRPIX2'])\n",
    "    \n",
    "    #Creates difference values that represent the start and end pixels of the resampled image on the reference image.\n",
    "    ref_x_start=int(reference[0].header['CRPIX1']-resampled[0].header['CRPIX1'])\n",
    "    ref_y_start=int(reference[0].header['CRPIX2']-resampled[0].header['CRPIX2'])\n",
    "    ref_x_end=int(reference[0].header['CRPIX1']+resdistx)\n",
    "    ref_y_end=int(reference[0].header['CRPIX2']+resdisty)\n",
    "    \n",
    "    #loading files into memory\n",
    "    refimg=pyfits.open(master_file[0])\n",
    "    resimg=pyfits.open(resamps[i])\n",
    "    segimg=pyfits.open(master_segmentation[0])\n",
    "    \n",
    "    #converting to array\n",
    "    D1=refimg[0].data\n",
    "    D2=resimg[0].data\n",
    "    D3=segimg[0].data\n",
    "    \n",
    "    #resizing and scaling pixel values\n",
    "    resize_ref=D1[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    resamp_scaled=D2*resampled[0].header['FLXSCALE']\n",
    "    resize_seg=D3[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    \n",
    "    #doing the subtraction of the reference image from the resampled\n",
    "    out_file=resamp_scaled-resize_ref\n",
    "    \n",
    "    #loading header information from original resampled image. This will be saved into the new images.\n",
    "    head=pyfits.getheader(resamps[i])\n",
    "    \n",
    "    #loads the filename of the resamp image into a variable, then deletes .resamp.fits from the end of it.\n",
    "    #This allows the code to write new files with the same naming format, but different file extension names.\n",
    "    #If your files don't end in .resamp.fits, the -12 will need to be changed to match the number of characters\n",
    "    #in the file extension.\n",
    "    path=os.path.basename(resamps[i])\n",
    "    new_path=path[:-12]\n",
    "    \n",
    "    #saves the final difference file, and the temporary resized segmentation map.\n",
    "    pyfits.writeto(('./Processed_Images/'+new_path+'.difference.fits'), out_file, head)\n",
    "    pyfits.writeto(('./Processed_Images/Temp/temp_segment.fits'), resize_seg, head)\n",
    "    \n",
    "    #produces a flag map from the temporary segmentation map.\n",
    "    subprocess.call('ww -c ./config_files/default.ww -WEIGHT_NAMES '+weights[i]+',./Processed_Images/Temp/temp_segment.fits', shell=True)\n",
    "    \n",
    "    #does the main sextractor run on the subtracted file, producing the object, background, and aperture files.\n",
    "    #this is controlled by default.sex in the config_files directory\n",
    "    subprocess.call('sex ./Processed_Images/'+new_path+'.difference.fits -c ./config_files/default.sex', shell=True)\n",
    "    \n",
    "    #cleans up temporary files and renames background, object, and aperture files. \n",
    "    subprocess.call('rm ./Processed_Images/Temp/temp_segment.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check.fits ./Processed_Images/'+new_path+'.background.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check2.fits ./Processed_Images/'+new_path+'.object.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check3.fits ./Processed_Images/'+new_path+'.apertures.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/weight.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/flag.fits',shell=True)\n",
    "#Uncomment the next line if you would like the code to automatically clean up the master segmentation map.\n",
    "#subprocess.call('rm ./Processed_Images/Temp/segmentation_map_ref.fits',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Begin Brendan's Transient checking script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is where the code can be tacked onto the pipeline, after subtracting reference images.\n",
    "# At this point we should have a combined image, with reference subtracted, where the only point sources remaining\n",
    "# (in theory) are transients such as supernovae or asteroids.\n",
    "\n",
    "# This code aims to classify such sources as either known asteroids or anomalies, which can then be manually checked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SExtractor once more to spot remaining (transient) sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate list of sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check against catalogues of known asteroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download latest MPCORB catalogue from:\n",
    "# www.minorplanetcenter.org/iau/MPCORB/MPCORB.DAT\n",
    "\n",
    "# Full list of paramters and how to read the data:\n",
    "# http://www.minorplanetcenter.net/iau/info/MPOrbitFormat.html\n",
    "\n",
    "\n",
    "# and do a manual check using PYEPHEM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fiddling around with pyephem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997/3/10 05:16:30\n",
      "1997/11/13 05:16:30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dates must be initialized from a number, string, tuple, or datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-389fa8b365ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# date method 3:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# this SHOULD return the same value as the above two.. not sure. will have to work around for now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mephem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1997/3/10 05:16:30'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: dates must be initialized from a number, string, tuple, or datetime"
     ]
    }
   ],
   "source": [
    "# The following 3 date entries should be indentical, but the preferred method (#3 below) is not recognised \n",
    "# for some reason...:\n",
    "\n",
    "# date method 1:\n",
    "print(ephem.Date(35497.7197916667))\n",
    "\n",
    "\n",
    "# date method 2:\n",
    "# Note: careful of  double parentheses; for some reason they are required.\n",
    "print(ephem.Date((1997, 11, 13, 5, 16, 30.0)))\n",
    "\n",
    "\n",
    "# date method 3:\n",
    "# this SHOULD return the same value as the above two.. not sure. will have to work around for now.\n",
    "print(ephem.Date('1997/3/10 05:16:30'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.906462 -0.293787\n",
      "3.907369 -0.291929\n",
      "0:07:03.0\n",
      "0:07:03.0\n"
     ]
    }
   ],
   "source": [
    "# Checking ephem.separation() function at time of Mercury transit.\n",
    "\n",
    "m = ephem.Mercury()\n",
    "m.compute((2006, 11, 8, 21, 41, 0))\n",
    "\n",
    "n = ephem.Sun()\n",
    "n.compute((2006, 11, 8, 21, 41, 0))\n",
    "\n",
    "print('%f %f' % (m.ra, m.dec))\n",
    "print ('%f %f' % (n.ra, n.dec))\n",
    "sep = ephem.separation(m,n)\n",
    "print(sep)\n",
    "print(ephem.degrees(sep))\n",
    "# Angular separation < 30 arcmin = transit :)\n",
    "# she works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the threshold is 0:20:00.0\n",
      "separation smaller than threshold.\n"
     ]
    }
   ],
   "source": [
    "if sep < ephem.degrees(0.00581776):\n",
    "    print('the threshold is ' + str(ephem.degrees(0.00581776)))\n",
    "    print('separation smaller than threshold.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:00:56.48  -21:30:08.1\n"
     ]
    }
   ],
   "source": [
    "m = ephem.Mars()\n",
    "d1 = ephem.Date((2009, 2, 2, 0, 0, 0))\n",
    "m.compute(d1)\n",
    "print(('%s  %s') %(m.ra, m.dec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MPCORB database and split into a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load MPCORB.DAT data into an array:\n",
    "# delimiter to split data into required columns\n",
    "# Add 'skip_header=41' parameter when using real data to skip header info\n",
    "# length of line = 202 characters\n",
    "# \n",
    "# names = ['designation', 'abs mag', 'slope param', 'epoch', 'mean epoch anomaly', 'perihelion arg', 'longitude', /\n",
    "# 'inclination', 'eccentricity', 'mean daily motion', 'semimajor axis', 'uncertainty', 'reference', 'num obs', /\n",
    "# 'num opp', 'obs years / arc length', 'rms', 'coarse perturb', 'precise perturb', 'comp name', '4hex flag', / \n",
    "# 'readable designation', 'last obs']\n",
    "\n",
    "MPCORB = np.genfromtxt('MPCORB/MPCORB_test', autostrip=True, dtype=str,  delimiter = [8,6,6,6,10,11,11,11,11,12,12,3,10,6,4,10,5,4,4,11,5,28,8])\n",
    "\n",
    "designation = MPCORB[:,0]\n",
    "abs_mag = MPCORB[:,1]\n",
    "slope_param = MPCORB[:,2]\n",
    "epoch = MPCORB[:,3]\n",
    "mean_epoch_anomaly = MPCORB[:,4]\n",
    "perihelion_arg = MPCORB[:,5]\n",
    "longitude = MPCORB[:,6]\n",
    "inclination = MPCORB[:,7]\n",
    "eccentricity = MPCORB[:,8]\n",
    "mean_daily_motion = MPCORB[:,9]\n",
    "semimajor_axis = MPCORB[:,10]\n",
    "uncertainty = MPCORB[:,11]\n",
    "reference = MPCORB[:,12]\n",
    "num_obs = MPCORB[:,13]\n",
    "num_opp = MPCORB[:,14]\n",
    "obs_years_arc_length = MPCORB[:,15]\n",
    "rms = MPCORB[:,16]\n",
    "coarse_perturb = MPCORB[:,17]\n",
    "precise_perturb = MPCORB[:,18]\n",
    "comp_name = MPCORB[:,19]\n",
    "hex_flag =  MPCORB[:,20]\n",
    "read_des = MPCORB[:,21]\n",
    "last_obs = MPCORB[:,22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to extract the packed Epoch date format given in the MPCORB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define dictionary of alpha to numbers for MPCORB packed dates translation:\n",
    "# see  <http://www.minorplanetcenter.net/iau/info/PackedDates.html>  for more info.\n",
    "\n",
    "def epoch_convert(date):\n",
    "    \n",
    "    \"Converts the MPCORB Epoch from packed form to a regular YYYYMMDD.DDDD string to be split up and used later.\"\n",
    "    \n",
    "    packeddates = {'1':'1', '2':'2', '3':'3', '4':'4', '5':'5', '6':'6', '7':'7', '8':'8', '9':'9', \\\n",
    "                   '0':'0', 'A':'10', 'B':'11', 'C':'12', 'D':'13', 'E':'14', 'F':'15', 'G':'16', \\\n",
    "                   'H':'17', 'I':'18', 'J':'19', 'K':'20', 'L':'21', 'M':'22', 'N':'23', 'O':'24', \\\n",
    "                   'P':'25', 'Q':'26', 'R':'27', 'S':'28','T':'29', 'U':'30', 'V':'31' \\\n",
    "              }\n",
    "    datestring = list(date[0:5])\n",
    "    datestring2 = \"\"\n",
    "    nums = \"0123456789\"\n",
    "    \n",
    "    # Conditionals to distinguish between packed dates, eg  avoid confusion between 1-Nov (11 1) /\n",
    "    # and 11-Jan (1 11) when compiled back into a string (111). \n",
    "    # We convert all single-digit numeric month/day values to 2-digits (eg 6 --> 06):\n",
    "    \n",
    "    if date[3] in nums and date[4] in nums:\n",
    "        datestring.insert(3,'0')\n",
    "        datestring.insert(5,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2 \n",
    "    elif date[3] in nums and date[4] not in nums:\n",
    "        datestring.insert(3,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    elif date[3] not in nums and date[4] in nums:\n",
    "        datestring.insert(4,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    elif date[3] not in nums and date[4] not in nums:\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    \n",
    "    print(datestring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'20160511.5566'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = 'K165B5566'\n",
    "epoch_convert(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20100723\n"
     ]
    }
   ],
   "source": [
    "for packed in epoch:\n",
    "    print('epoch: ' + epoch_convert(packed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NEED TO NOW ASSIGN THE ORBITAL PARAMS TO AN OBJECT.\n",
    "# CHECK THE RA DEC AT SOME ARBITRARY TIME, SEE IF SHE WORKS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some asteroid parameters into pyephem to test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required orbital params:\n",
    "\n",
    "N (= Om) = longitude of the ascending node \n",
    "\n",
    "i (= inc) = inclination to the ecliptic (plane of the Earth's orbit)\n",
    "\n",
    "w (= om) = argument of perihelion\n",
    "\n",
    "a = semi-major axis, or mean distance from Sun\n",
    "\n",
    "e = eccentricity (0=circle, 0-1=ellipse, 1=parabola)\n",
    "\n",
    "M = mean anomaly (0 at perihelion; increases uniformly with time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160113\n",
      "2016/1/13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# initialise a new, blank orbital body and load orbital params:\n",
    "params = MPCORB[0]\n",
    "body = ephem.EllipticalBody()\n",
    "\n",
    "#six required params for Keplerian orbit:\n",
    "# Longitude of ascending node:\n",
    "body._Om = float(params[6])\n",
    "# Inclination:\n",
    "body._inc = float(params[7])\n",
    "# Arg of perihelion\n",
    "body._om = float(params[5])\n",
    "# Mean distance from Sun: ???????????? ACCURATE?? Semi Major Axis, technically.\n",
    "body._a = float(params[10])\n",
    "# Eccentricity:\n",
    "body._e = float(params[8])\n",
    "# Mean anomoly from perihelion:\n",
    "body._M = float(params[4])\n",
    "# Epoch for _M:\n",
    "body._epoch_M = ephem.Date((2016, 1, 13, 0, 0, 0))\n",
    "\n",
    "print(epoch_convert('K161D'))\n",
    "print(body._epoch_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016/1/17 00:00:00\n",
      "RA: 0:54:35.42, DEC: -1:19:27.4\n"
     ]
    }
   ],
   "source": [
    "#Vesta correct RA DEC for Jan 19, 2016: RA: 0h51m20s, DEC: -1 31' 10\"\n",
    "date1 = ephem.Date((2016, 1, 17, 0, 0, 0))\n",
    "body.compute(date1)\n",
    "print(date1)\n",
    "print('RA: ' +str(body.ra) +', DEC: '+ str(body.dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Possible requirement for rectifying discrepencies?\n",
    "# http://www.stjarnhimlen.se/comp/ppcomp.html#16\n",
    "\n",
    "# Correction for precession:?\n",
    "# N = N_Epoch + 0.013967 * ( 2000.0 - Epoch ) + 3.82394E-5 * d\n",
    "\n",
    "#and mean daily motion n required too:?\n",
    "#mdm = aasdasdsads\n",
    "\n",
    "\n",
    "#print(body._Om, body._inc, body._om, body._a, body._e, body._M)?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test reading fits header for pulling date and time of image and store as string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "light = '2014-09-21_83F011167_12_light.bdfw.fits'\n",
    "datestr = fits.getheader(light)['DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-09-21T15:05:59'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/9/21 15:05:59\n"
     ]
    }
   ],
   "source": [
    "print(ephem.Date((int(datestr[0:4]), int(datestr[5:7]), int(datestr[8:10]), int(datestr[11:13]), \\\n",
    "                  int(datestr[14:16]), int(datestr[17:19]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search MPCORB for matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nest this loop outside the MPCORB search loop:\n",
    "# for trans in translist:\n",
    "    # RA = trans.header[\"RA\"]\n",
    "    # DEC = trans.header[\"DEC\"]\n",
    "    # obstime = trans.header[\"DATE\"]\n",
    "    # identcount = 0\n",
    "    # for object in MPCORB:\n",
    "        # .......\n",
    "    \n",
    "    # if identcount = 0 (no object found):\n",
    "        # anom.append(\"object designation\", \"object name\" \"trans WCS at that time\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ayear = int(datestr[0:4])\n",
    "amonth = int(datestr[5:7])\n",
    "aday = int(datestr[8:10])\n",
    "ahour = int(datestr[11:13])\n",
    "amin = int(datestr[14:16])\n",
    "asec = int(datestr[17:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/9/21 15:05:59\n"
     ]
    }
   ],
   "source": [
    "print(ephem.Date((ayear, amonth, aday, ahour, amin, asec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "For MP in MPCORB:\n",
    "    inc = \n",
    "     = \n",
    "    newobject = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    # convert orbital params at given date to RA/DEC\n",
    "    # Vec = vectorize (trans RA & DEC) with (MPCORB object RA & DEC)\n",
    "    # if Vec <= threshold (20 arcmin?):\n",
    "        # ident.append(\"object designation\", \"object name\" \"object WCS at that time\", \"distance vector from trans\")\n",
    "        # identcount += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pyephem, take WCS of anomalies, if pyephem of each oject in MPCORB is within a threshold (vectorize) at that time, then return object\n",
    "# else, return anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "print(len('00001    3.34  0.12 K161D 181.38133   72.73324   80.32180   10.59166  0.0757544  0.21400734   2.7681117  0 MPO358623  6592 109 1801-2015 0.60 M-v 30h MPCLINUX   0000      (1) Ceres              20151128'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
