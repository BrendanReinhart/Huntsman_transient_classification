{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Transient Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import time\n",
    "#import os\n",
    "#import glob\n",
    "#import subprocess\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import sys\n",
    "import datetime\n",
    "import ephem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can add the below process to the existing Transients code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This section tells the code where the files are. \n",
    "#data_path should point to the directory that holds the .resamp.fits files \n",
    "#produced by swarp (usually by Jack's Code)\n",
    "data_path = ('./output/Temp/')\n",
    "\n",
    "#master_file is the final processed image made from the above resamp files.\n",
    "master_file = ['./output/coadd_ngc300_r.fits']\n",
    "\n",
    "#master_weight is the weight file which corresponds to the above master file.\n",
    "master_weight = ['./output/coadd_ngc300_r.weight.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These variables are lists of the resampled files and their corresponding weights.\n",
    "\n",
    "resamps=sorted(glob.glob(data_path+'*.resamp.fits'))\n",
    "weights=sorted(glob.glob(data_path+'*.resamp.weight.fits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates a segmentation map from the master file. This will be used to generate flag files later.\n",
    "#To tweak the sensitivity of this segmentation map (brightness of objects it identifies for flagging), change\n",
    "#the DETECT_THRESH and ANALYSIS_THRESH values in segmentation.sex, located in the config_files directory.\n",
    "#This file is a temporary file, but the code will not delete it by default, as it can be a useful analysis tool.\n",
    "\n",
    "subprocess.call('sex '+master_file[0]+' -c ./config_files/segmentation.sex -WEIGHT_IMAGE '+master_weight[0], shell=True)\n",
    "subprocess.call('mv ./Processed_Images/Temp/check.fits ./Processed_Images/Temp/segmentation_map_ref.fits', shell=True)\n",
    "master_segmentation = ['./Processed_Images/Temp/segmentation_map_ref.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This loop creates all the difference images and their respective object, background, and aperture maps.\n",
    "\n",
    "for i in range(0,2):#len(resamps)):\n",
    "    reference=fits.open(master_file[0])\n",
    "    resampled=fits.open(resamps[i])\n",
    "    \n",
    "    #measures the distance from the central WCS pixel to the right and to the bottom of the image, respectively.\n",
    "    resdistx=(resampled[0].header['NAXIS1']-resampled[0].header['CRPIX1'])\n",
    "    resdisty=(resampled[0].header['NAXIS2']-resampled[0].header['CRPIX2'])\n",
    "    \n",
    "    #Creates difference values that represent the start and end pixels of the resampled image on the reference image.\n",
    "    ref_x_start=int(reference[0].header['CRPIX1']-resampled[0].header['CRPIX1'])\n",
    "    ref_y_start=int(reference[0].header['CRPIX2']-resampled[0].header['CRPIX2'])\n",
    "    ref_x_end=int(reference[0].header['CRPIX1']+resdistx)\n",
    "    ref_y_end=int(reference[0].header['CRPIX2']+resdisty)\n",
    "    \n",
    "    #loading files into memory\n",
    "    refimg=pyfits.open(master_file[0])\n",
    "    resimg=pyfits.open(resamps[i])\n",
    "    segimg=pyfits.open(master_segmentation[0])\n",
    "    \n",
    "    #converting to array\n",
    "    D1=refimg[0].data\n",
    "    D2=resimg[0].data\n",
    "    D3=segimg[0].data\n",
    "    \n",
    "    #resizing and scaling pixel values\n",
    "    resize_ref=D1[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    resamp_scaled=D2*resampled[0].header['FLXSCALE']\n",
    "    resize_seg=D3[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    \n",
    "    #doing the subtraction of the reference image from the resampled\n",
    "    out_file=resamp_scaled-resize_ref\n",
    "    \n",
    "    #loading header information from original resampled image. This will be saved into the new images.\n",
    "    head=pyfits.getheader(resamps[i])\n",
    "    \n",
    "    #loads the filename of the resamp image into a variable, then deletes .resamp.fits from the end of it.\n",
    "    #This allows the code to write new files with the same naming format, but different file extension names.\n",
    "    #If your files don't end in .resamp.fits, the -12 will need to be changed to match the number of characters\n",
    "    #in the file extension.\n",
    "    path=os.path.basename(resamps[i])\n",
    "    new_path=path[:-12]\n",
    "    \n",
    "    #saves the final difference file, and the temporary resized segmentation map.\n",
    "    pyfits.writeto(('./Processed_Images/'+new_path+'.difference.fits'), out_file, head)\n",
    "    pyfits.writeto(('./Processed_Images/Temp/temp_segment.fits'), resize_seg, head)\n",
    "    \n",
    "    #produces a flag map from the temporary segmentation map.\n",
    "    subprocess.call('ww -c ./config_files/default.ww -WEIGHT_NAMES '+weights[i]+',./Processed_Images/Temp/temp_segment.fits', shell=True)\n",
    "    \n",
    "    #does the main sextractor run on the subtracted file, producing the object, background, and aperture files.\n",
    "    #this is controlled by default.sex in the config_files directory\n",
    "    subprocess.call('sex ./Processed_Images/'+new_path+'.difference.fits -c ./config_files/default.sex', shell=True)\n",
    "    \n",
    "    #cleans up temporary files and renames background, object, and aperture files. \n",
    "    subprocess.call('rm ./Processed_Images/Temp/temp_segment.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check.fits ./Processed_Images/'+new_path+'.background.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check2.fits ./Processed_Images/'+new_path+'.object.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check3.fits ./Processed_Images/'+new_path+'.apertures.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/weight.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/flag.fits',shell=True)\n",
    "#Uncomment the next line if you would like the code to automatically clean up the master segmentation map.\n",
    "#subprocess.call('rm ./Processed_Images/Temp/segmentation_map_ref.fits',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Begin Brendan's Transient checking script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is where the code can be tacked onto the pipeline, after subtracting reference images.\n",
    "# At this point we should have a combined image, with reference subtracted, where the only point sources remaining\n",
    "# (in theory) are transients such as supernovae or asteroids.\n",
    "\n",
    "# This code aims to classify such sources as either known asteroids or anomalies, which can then be manually checked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SExtractor once more to spot remaining (transient) sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate list of sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check against catalogues of known asteroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download latest MPCORB catalogue from:\n",
    "# www.minorplanetcenter.org/iau/MPCORB/MPCORB.DAT\n",
    "\n",
    "# Full list of paramters and how to read the data:\n",
    "# http://www.minorplanetcenter.net/iau/info/MPOrbitFormat.html\n",
    "\n",
    "\n",
    "# and do a manual check using PYEPHEM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fiddling around with pyephem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997/3/10 05:16:30\n",
      "2015/5/22 10:56:38\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dates must be initialized from a number, string, tuple, or datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-61d6832e6c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# date method 3:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# this SHOULD return the same value as the above two.. not sure. will have to work around for now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mephem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1997/03/10 05:16:30.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dates must be initialized from a number, string, tuple, or datetime"
     ]
    }
   ],
   "source": [
    "# The following 3 date entries should be indentical, but the preferred method (#3 below) is not recognised \n",
    "# for some reason...:\n",
    "\n",
    "# date method 1:\n",
    "print(ephem.Date(35497.7197916667))\n",
    "\n",
    "# date method 2:\n",
    "# Note: careful of  double parentheses; for some reason they are required.\n",
    "efg = ephem.Date((1997, 11, 13, 5, 16, 30.0))\n",
    "hhh = (2015, 5, 22.456)\n",
    "print(ephem.Date(hhh))\n",
    "\n",
    "\n",
    "# date method 3:\n",
    "# this SHOULD return the same value as the above two.. not sure. will have to work around for now.\n",
    "d = ephem.Date('1997/03/10 05:16:30.0')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:50:34.32 -8:13:23.5\n",
      "14:55:30.18 -16:43:34.6\n",
      "114:31:07.0\n",
      "114:31:07.0\n"
     ]
    }
   ],
   "source": [
    "# Checking ephem.separation() function at time of Mercury transit.\n",
    "\n",
    "m = ephem.Uranus()\n",
    "m.compute((2006, 11, 8, 21, 41, 0))\n",
    "\n",
    "n = ephem.Sun()\n",
    "n.compute((2006, 11, 8, 21, 41, 0))\n",
    "\n",
    "print(m.ra, m.dec)\n",
    "print (n.ra, n.dec)\n",
    "sep = ephem.separation(m,n)\n",
    "print(sep)\n",
    "print(ephem.degrees(sep))\n",
    "# Angular separation < 30 arcmin = transit :)\n",
    "# she works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114:31:07.0\n"
     ]
    }
   ],
   "source": [
    "if sep < ephem.degrees(0.00581776):\n",
    "    print('the threshold is ' + str(ephem.degrees(0.00581776)))\n",
    "    print('separation smaller than threshold.')\n",
    "else:\n",
    "    print(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:00:56.48  -21:30:08.1\n"
     ]
    }
   ],
   "source": [
    "m = ephem.Mars()\n",
    "d1 = ephem.Date((2009, 2, 2, 0, 0, 0))\n",
    "m.compute(d1)\n",
    "print(('%s  %s') %(m.ra, m.dec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MPCORB database and split into a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load MPCORB.DAT data into an array:\n",
    "# delimiter to split data into required columns\n",
    "# Add 'skip_header=41' parameter when using real data to skip header info\n",
    "# length of line = 202 characters\n",
    "# \n",
    "# names = ['designation', 'abs mag', 'slope param', 'epoch', 'mean epoch anomaly', 'perihelion arg', 'longitude', /\n",
    "# 'inclination', 'eccentricity', 'mean daily motion', 'semimajor axis', 'uncertainty', 'reference', 'num obs', /\n",
    "# 'num opp', 'obs years / arc length', 'rms', 'coarse perturb', 'precise perturb', 'comp name', '4hex flag', / \n",
    "# 'readable designation', 'last obs']\n",
    "\n",
    "MPCORB = np.genfromtxt('MPCORB/MPCORB_test', autostrip=True, dtype=str,  delimiter = [8,6,6,6,10,11,11,11,11,12,12,3,10,6,4,10,5,4,4,11,5,28,8])\n",
    "\n",
    "designation = MPCORB[:,0]\n",
    "abs_mag = MPCORB[:,1]\n",
    "slope_param = MPCORB[:,2]\n",
    "epoch = MPCORB[:,3]\n",
    "mean_epoch_anomaly = MPCORB[:,4]\n",
    "perihelion_arg = MPCORB[:,5]\n",
    "longitude = MPCORB[:,6]\n",
    "inclination = MPCORB[:,7]\n",
    "eccentricity = MPCORB[:,8]\n",
    "mean_daily_motion = MPCORB[:,9]\n",
    "semimajor_axis = MPCORB[:,10]\n",
    "uncertainty = MPCORB[:,11]\n",
    "reference = MPCORB[:,12]\n",
    "num_obs = MPCORB[:,13]\n",
    "num_opp = MPCORB[:,14]\n",
    "obs_years_arc_length = MPCORB[:,15]\n",
    "rms = MPCORB[:,16]\n",
    "coarse_perturb = MPCORB[:,17]\n",
    "precise_perturb = MPCORB[:,18]\n",
    "comp_name = MPCORB[:,19]\n",
    "hex_flag =  MPCORB[:,20]\n",
    "read_des = MPCORB[:,21]\n",
    "last_obs = MPCORB[:,22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to extract the packed Epoch date format given in the MPCORB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define dictionary of alpha to numbers for MPCORB packed dates translation:\n",
    "# see  <http://www.minorplanetcenter.net/iau/info/PackedDates.html>  for more info.\n",
    "\n",
    "def epoch_convert(date):\n",
    "    \n",
    "    \"Converts the MPCORB Epoch from packed form to a regular YYYYMMDD.DDDD string to be split up and used later.\"\n",
    "    \n",
    "    packeddates = {'1':'1', '2':'2', '3':'3', '4':'4', '5':'5', '6':'6', '7':'7', '8':'8', '9':'9', \\\n",
    "                   '0':'0', 'A':'10', 'B':'11', 'C':'12', 'D':'13', 'E':'14', 'F':'15', 'G':'16', \\\n",
    "                   'H':'17', 'I':'18', 'J':'19', 'K':'20', 'L':'21', 'M':'22', 'N':'23', 'O':'24', \\\n",
    "                   'P':'25', 'Q':'26', 'R':'27', 'S':'28','T':'29', 'U':'30', 'V':'31' \\\n",
    "              }\n",
    "    datestring = list(date[0:5])\n",
    "    datestring2 = \"\"\n",
    "    nums = \"0123456789\"\n",
    "    \n",
    "    # Conditionals to distinguish between packed dates, eg  avoid confusion between 1-Nov (11 1) /\n",
    "    # and 11-Jan (1 11) when compiled back into a string (111). \n",
    "    # We convert all single-digit numeric month/day values to 2-digits (eg 6 --> 06):\n",
    "    \n",
    "    if date[3] in nums and date[4] in nums:\n",
    "        datestring.insert(3,'0')\n",
    "        datestring.insert(5,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2 \n",
    "    elif date[3] in nums and date[4] not in nums:\n",
    "        datestring.insert(3,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    elif date[3] not in nums and date[4] in nums:\n",
    "        datestring.insert(4,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    elif date[3] not in nums and date[4] not in nums:\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    \n",
    "    print(datestring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160511.5566\n",
      "(2016, 5, 11.5566)\n",
      "2016/5/11 13:21:30\n",
      "20160511.5566\n"
     ]
    }
   ],
   "source": [
    "test1 = 'K165B5566'\n",
    "test2 = epoch_convert(test1)\n",
    "print(test2)\n",
    "hhh = (int(test2[:4]), int(test2[4:6]), float(test2[6:]))\n",
    "print(hhh)\n",
    "print(ephem.Date(hhh))\n",
    "print('%s' % (test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 5 11.5566\n",
      "2016/5/11 06:09:30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42500.0566"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = int(test2[:4])\n",
    "b = int(test2[5:6])\n",
    "c = float(test2[6:])\n",
    "print(a, b, c)\n",
    "print(ephem.Date((2016, 5, 11.2566)))\n",
    "ephem.Date((a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016/5/11 13:21:30\n"
     ]
    }
   ],
   "source": [
    "print(ephem.Date((int(test2[:4]), int(test2[4:6]), float(test2[6:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20160113\n",
      "epoch: 20100723\n"
     ]
    }
   ],
   "source": [
    "for packed in epoch:\n",
    "    print('epoch: ' + epoch_convert(packed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some asteroid parameters into pyephem to test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required orbital params:\n",
    "\n",
    "Om longitude of the ascending node \n",
    "\n",
    "inc = inclination to the ecliptic (plane of the Earth's orbit)\n",
    "\n",
    "om = argument of perihelion\n",
    "\n",
    "a = semi-major axis, or mean distance from Sun\n",
    "\n",
    "e = eccentricity (0=circle, 0-1=ellipse, 1=parabola)\n",
    "\n",
    "M = mean anomaly (0 at perihelion; increases uniformly with time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Ephemeris calculation for a real asteroid, Vesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016/1/19 00:00:00\n",
      "['00004' '3.20' '0.32' 'K161D' '129.52980' '151.13748' '103.84611'\n",
      " '7.14005' '0.0889223' '0.27156600' '2.3616695' '0' 'MPO358623' '6811' '98'\n",
      " '1821-2015' '0.60' 'M-p' '18h' 'MPCLINUX' '0000' '(4) Vesta' '20151215']\n"
     ]
    }
   ],
   "source": [
    "# initialise a new, blank orbital body and load orbital params:\n",
    "params = MPCORB[0]\n",
    "body = ephem.EllipticalBody()\n",
    "\n",
    "#six required params for Keplerian orbit:\n",
    "# Longitude of ascending node:\n",
    "body._Om = float(params[6])\n",
    "# Inclination:\n",
    "body._inc = float(params[7])\n",
    "# Arg of perihelion\n",
    "body._om = float(params[5])\n",
    "# Mean distance from Sun: ???????????? ACCURATE?? Semi Major Axis, technically.\n",
    "body._a = float(params[10])\n",
    "# Eccentricity:\n",
    "body._e = float(params[8])\n",
    "# Mean anomoly from perihelion:\n",
    "body._M = float(params[4])\n",
    "# Epoch for _M:\n",
    "aster_epoch = epoch_convert('K161D')\n",
    "#body._epoch_M = ephem.Date((int(aster_epoch[:4]), int(aster_epoch[4:6]), float(aster_epoch[6:])))\n",
    "body._epoch_M = ephem.Date((2016, 01, 19))\n",
    "\n",
    "\n",
    "huntsman = ephem.Observer()\n",
    "huntsman.lon = 151.111128\n",
    "huntsman.lat = -33.770281\n",
    "huntsman.elevation = 50\n",
    "huntsman.date = ephem.Date((2016, 1, 19, 0, 0, 0))\n",
    "huntsman.epoch=ephem.J2000\n",
    "#get fits header for date\n",
    "\n",
    "\n",
    "print(body._epoch_M)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:51:07.93 -1:35:30.5\n",
      "0:51:56.80 -1:30:23.6\n",
      "0:51:56.94 -1:30:21.3\n"
     ]
    }
   ],
   "source": [
    "body.compute(huntsman)\n",
    "print(body.a_ra, body.a_dec)\n",
    "print(body.g_ra, body.g_dec)\n",
    "print(body.ra, body.dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016/1/19 00:00:00\n",
      "(4) Vesta\n",
      "Apparent Topocentric Positio:      RA: 0:51:56.80, DEC: -1:30:23.6\n",
      "Astrometric Geocentric Position:   RA: 0:51:07.93, DEC: -1:35:30.5\n",
      "Apparent Geocentric Position:      RA: 0:51:56.80, DEC: -1:30:23.6\n"
     ]
    }
   ],
   "source": [
    "date1 = ephem.Date((2016, 1, 19, 0, 0, 0))\n",
    "body.compute(date1)\n",
    "print(date1)\n",
    "print(params[21])\n",
    "print('Apparent Topocentric Positio:      RA: ' +str(body.ra) +', DEC: '+ str(body.dec))\n",
    "print('Astrometric Geocentric Position:   RA: ' +str(body.a_ra) +', DEC: '+ str(body.a_dec))\n",
    "print('Apparent Geocentric Position:      RA: ' +str(body.g_ra) +', DEC: '+ str(body.g_dec))\n",
    "\n",
    "# Correct values for 19 Jan 2016 0:00:00  as per <ssd.jpl.nasa.gov/horizons.cgi>:\n",
    "# 00 52 10.62 -01 26 01.5       \n",
    " \n",
    "# See what values we get for our data!\n",
    "\n",
    "# This was tested at most recent epoch. Test further away from this to check how fast errors will accumulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### test reading fits header for pulling date and time of image and store as string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-09-21T15:05:59'"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light = '2014-09-21_83F011167_12_light.bdfw.fits'\n",
    "datestr = fits.getheader(light)['DATE']\n",
    "datestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/9/21 15:05:59\n"
     ]
    }
   ],
   "source": [
    "print(ephem.Date((int(datestr[0:4]), int(datestr[5:7]), int(datestr[8:10]), int(datestr[11:13]), \\\n",
    "                  int(datestr[14:16]), int(datestr[17:19]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can use this to calculate day fractionals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2014, 9, 21.629155092588917)\n"
     ]
    }
   ],
   "source": [
    "d = ephem.Date((2014, 9, 21, 15, 5, 59))\n",
    "print(d.triple())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final code to check series of images against MPCORB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:54:53.5\n",
      "0:54:53.50 -37:41:04.0\n",
      "Asteroid (4) Vesta is at RA 0:52:30.75  Dec -1:21:10.8\n",
      "MP body (4) Vesta is not within the threshold.. (4) Vesta is 36:20:17.9 degrees away from transient.\n",
      "Asteroid (5) Astraea is at RA 10:11:03.49  Dec 10:20:02.1\n",
      "MP body (5) Astraea is not within the threshold.. (5) Astraea is 134:14:17.1 degrees away from transient.\n",
      "Asteroid (6) Hebe is at RA 12:32:28.97  Dec 5:54:07.3\n",
      "MP body (6) Hebe is not within the threshold.. (6) Hebe is 147:48:20.0 degrees away from transient.\n",
      "Asteroid (7) Iris is at RA 15:57:50.80  Dec -23:13:38.8\n",
      "MP body (7) Iris is not within the threshold.. (7) Iris is 105:27:12.7 degrees away from transient.\n",
      "Asteroid (8) Flora is at RA 16:17:50.28  Dec -16:49:26.2\n",
      "MP body (8) Flora is not within the threshold.. (8) Flora is 107:36:22.5 degrees away from transient.\n",
      "Asteroid (9) Metis is at RA 0:05:00.69  Dec -3:17:32.8\n",
      "MP body (9) Metis is not within the threshold.. (9) Metis is 36:14:31.2 degrees away from transient.\n",
      "Asteroid (10) Hygiea is at RA 11:58:45.05  Dec -4:25:02.5\n",
      "MP body (10) Hygiea is not within the threshold.. (10) Hygiea is 135:55:09.2 degrees away from transient.\n",
      "Asteroid 2010 OU100 is at RA 17:08:04.12  Dec -30:39:24.3\n",
      "MP body 2010 OU100 is not within the threshold.. 2010 OU100 is 89:40:15.7 degrees away from transient.\n",
      "No asteroid located within 5:00:00.0 degrees of position RA: 0:54:53.50 Dec: -37:41:04.0 at time 2016/1/20 00:00:00\n",
      "completed in 0.00146889686584 seconds\n"
     ]
    }
   ],
   "source": [
    "# will need to isolate the RA/Dec of potential transients identified in SExtractor first. Then check for time/date on \n",
    "# processed image. \n",
    "\n",
    "\n",
    "#lights = (list of images with transient source data)\n",
    "\n",
    "## Temporary data, will be replaced with actual FITS images ideally, or some other way to extract the required info\n",
    "# (eg list with WCS, temp, date and time?)\n",
    "lights = [['2016-01-20T00:00:00', '00:54:53.5', '-37:41:04']]\n",
    "\n",
    "huntsman = ephem.Observer()\n",
    "huntsman.lon = 149.067307\n",
    "huntsman.lat = -31.274587\n",
    "huntsman.elevation = 510    # Average alt. of Coona. Needs updating when dome/mount contructed.\n",
    "\n",
    "a = time.time()\n",
    "for image in lights:\n",
    "    transcoords = ephem.FixedBody()   # create fixed object to hold RA dec coords??\n",
    "    #transcoords = ephem.FixedBody(float(fits.getheader(image)['OBJECTRA']), float(fits.getheader(image)['OBJECTDEC']))\n",
    "    transcoords._ra = image[1]\n",
    "    transcoords._dec = image[2]\n",
    "    transcoords.compute()\n",
    "    print(image[1])\n",
    "    print(transcoords._ra, transcoords._dec)\n",
    "    #datestr = fits.getheader(image)['DATE']                      # get date/time from fits header\n",
    "    datestr = image[0]\n",
    "    huntsman.date = ephem.Date((int(datestr[0:4]), int(datestr[5:7]), int(datestr[8:10]), \\\n",
    "                                int(datestr[11:13]), int(datestr[14:16]), int(datestr[17:19])))\n",
    "                                                                 # ^ get the date/time from the fits header\n",
    "    identcount = 0                                               # initialize a new count of identified objects\n",
    "    for MP in MPCORB:\n",
    "        newbody = ephem.EllipticalBody()\n",
    "        # Longitude of ascending node:\n",
    "        newbody._Om = float(MP[6])\n",
    "        # Inclination:\n",
    "        newbody._inc = float(MP[7])\n",
    "        # Arg of perihelion\n",
    "        newbody._om = float(MP[5])\n",
    "        # Mean distance from Sun: ???????????? ACCURATE?? Semi Major Axis, technically.\n",
    "        newbody._a = float(MP[10])\n",
    "        # Eccentricity:\n",
    "        newbody._e = float(MP[8])\n",
    "        # Mean anomoly from perihelion:\n",
    "        newbody._M = float(MP[4])\n",
    "        # Epoch = J2000:\n",
    "        newbody._epoch = ephem.J2000\n",
    "        # Epoch for _M:\n",
    "        aster_epoch_str = epoch_convert(MP[3])\n",
    "        aster_year = int(aster_epoch_str[:4])\n",
    "        aster_month = int(aster_epoch_str[4:6])\n",
    "        aster_day = float(aster_epoch_str[6:])\n",
    "        aster_epoch = ephem.Date((aster_year, aster_month, aster_day))\n",
    "        newbody._epoch_M = aster_epoch\n",
    "                \n",
    "        newbody.compute(huntsman)\n",
    "        sep = ephem.separation(newbody, transcoords)\n",
    "        print('Asteroid %s is at RA %s  Dec %s' % (MP[21], newbody.a_ra, newbody.a_dec))\n",
    "        if sep < ephem.degrees(0.0872665):\n",
    "            identcount += 1\n",
    "            print('%s asteroid(s) found: ' %(identcount))\n",
    "            print('%s is approximately %s degrees from potential transient source' % (MP[21], sep))\n",
    "            # possibly also document them into a txt file?\n",
    "        else:\n",
    "            print('MP body %s is not within the threshold.. %s is %s degrees away from transient.' %(MP[21], MP[21], sep))\n",
    "    if identcount == 0:\n",
    "        print('No asteroid located within %s degrees of position RA: %s Dec: %s at time %s' %(ephem.degrees(0.0872665), transcoords._ra, transcoords._dec, huntsman.date))\n",
    "    else:\n",
    "        print()\n",
    "        \n",
    "b = time.time()\n",
    "print('completed in', b-a, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pyephem, take WCS of anomalies, if pyephem of each oject in MPCORB is within a threshold (vectorize) at that time, then return object\n",
    "# else, return anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "print(len('00001    3.34  0.12 K161D 181.38133   72.73324   80.32180   10.59166  0.0757544  0.21400734   2.7681117  0 MPO358623  6592 109 1801-2015 0.60 M-v 30h MPCLINUX   0000      (1) Ceres              20151128'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
